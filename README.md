# MoodLens â€“ Real-Time Facial Emotion Detection with Voice Feedback

MoodLens is an AI-powered **real-time facial emotion detection** system built using **Python**, **OpenCV**, **MediaPipe**, **TensorFlow/Keras**, and **pyttsx3** for voice feedback.  
It detects human emotions from live camera feed and audibly announces them, making it both **interactive** and **accessible**.

---

## Features

- **Real-Time Detection** â€“ Uses webcam feed to detect faces and classify emotions instantly.
- **Voice Feedback** â€“ Announces detected emotions using the `pyttsx3` text-to-speech engine.
- **Multiple Emotions Supported** â€“ Detects emotions like Happy, Sad, Angry, Surprised, Neutral, etc.
- **Custom Dataset Support** â€“ Easily replace with your own dataset for fine-tuning.
- **Lightweight & Fast** â€“ Optimized for real-time inference using TensorFlow/Keras.
- **Cross-Platform** â€“ Works on Windows, macOS, and Linux.

---

## Technologies Used

- **Python** â€“ Core programming language.
- **OpenCV** â€“ For face detection and real-time video feed handling.
- **MediaPipe** â€“ For accurate and lightweight face landmark detection.
- **TensorFlow & Keras** â€“ For building and training the deep learning model.
- **NumPy** â€“ For numerical operations.
- **pyttsx3** â€“ For converting detected emotions to voice output.
- **Custom CNN Model** â€“ Pre-trained and saved as `emotion_model.h5`.

---

## Requirements

Before running MoodLens, install the required dependencies:

```bash
pip install opencv-python mediapipe tensorflow numpy pyttsx3
```

---

## Implementation Process

1ï¸âƒ£ Prepare Dataset

- **Download an emotion detection dataset** (https://www.kaggle.com/datasets/msambare/fer2013).

- **Organize images into**:

-**dataset/train/<emotion_name>/**

-**dataset/test/<emotion_name>/**


2ï¸âƒ£ Train the Model

- **Run the training script**:
```bash
python train_model.py
```

**This will**:

-**Load and preprocess images.**

-**Train a CNN model on the dataset.**

-**Save the trained model as model/emotion_model.h5.**



3ï¸âƒ£ Run Real-Time Detection

**Start the main script**:
```bash
python main.py
```
**The program will**:

-**Open webcam feed.**

-**Detect faces using MediaPipe.**

-**Predict emotion using the trained model.**

-**Announce detected emotion via voice.**

---

## How It Works

- **Face Detection â€“ MediaPipe detects and crops the face region from the webcam feed.**
- **Preprocessing â€“ The cropped face is resized and normalized for model input.**
- **Emotion Classification â€“ The trained CNN predicts the probability for each emotion.**
- **Voice Output â€“ The top predicted emotion is spoken aloud using pyttsx3.**
- **Real-Time Display â€“ The detected emotion is displayed on the webcam window.**

---
## Project Folder Structure

```
MoodLens/
â”œâ”€â”€ dataset/
â”‚   â”œâ”€â”€ train/
â”‚   â””â”€â”€ test/
â”œâ”€â”€ model/
â”‚   â”œâ”€â”€ emotion_labels.py
â”‚   â””â”€â”€ emotion_model.h5
â”œâ”€â”€ train_model.py
â”œâ”€â”€ main.py
```
---
## Demo ğŸ‘‰ğŸ» [photo](file_00000000238461f89d57ab2f469fbf53.png)
---
## Team Members
- [Aditya Kumar](https://github.com/baisoyaaditya)
- [Abhishek Solanki](https://github.com/abhisheksolanki18)
- [Ankit Kushwaha](https://github.com/ankitthakur7)
- [Abhishek Parmar](https://github.com/abhishekparmar2005)
